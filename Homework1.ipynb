{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMwp1Fqq2/9wg5536SGDXfg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hpatel295/IS465/blob/master/Homework1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU2Xvv4DG1XO",
        "colab_type": "text"
      },
      "source": [
        "Type anything you want \n",
        "especially for instruction \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DpY06DxG-yq",
        "colab_type": "code",
        "outputId": "f79be117-b4c2-4360-a079-bac0895cecd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print ('Hello World!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello World!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-GUkGMAHhU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
        "#         Lars Buitinck\n",
        "#         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
        "# License: BSD 3 clause"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Y8tmJ7IUjL",
        "colab_type": "text"
      },
      "source": [
        "import some packages: \n",
        "time is a python time library \n",
        "\n",
        "web mining is mining the text 1/6 2/6... \n",
        "web mining is fun 1/4\n",
        "i like this class 1/4 \n",
        "idf log 3/2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxN7-1scIXq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0gxnDsMKmI0",
        "colab_type": "text"
      },
      "source": [
        "define varibble "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovK6CA8AIe2n",
        "colab_type": "code",
        "outputId": "72906e65-0777-4ec8-d56d-ba98e6df8f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "n_samples = 2000\n",
        "n_features = 1000\n",
        "n_components = 10\n",
        "n_top_words = 20\n",
        "print(n_samples)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7RjEb6gKkPy",
        "colab_type": "text"
      },
      "source": [
        "define functions \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA0XQZr1Klm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        message = \"Topic #%d: \" % topic_idx\n",
        "        message += \" \".join([feature_names[i]\n",
        "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
        "        print(message)\n",
        "    print()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pYl0nbOLS6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
        "# to filter out useless terms early on: the posts are stripped of headers,\n",
        "# footers and quoted replies, and common English words, words occurring in\n",
        "# only one document or in at least 95% of the documents are removed.\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "t0 = time()\n",
        "data, _ = fetch_20newsgroups(shuffle=True, random_state=1,\n",
        "                             remove=('headers', 'footers', 'quotes'),\n",
        "                             return_X_y=True)\n",
        "data_samples = data[:n_samples]\n",
        "print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBXP7Bfdh1pK",
        "colab_type": "text"
      },
      "source": [
        "# Fit the NMF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8QC_Ihthnoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use tf-idf features for NMF.\n",
        "print(\"Extracting tf-idf features for NMF...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
        "                                   max_features=n_features,\n",
        "                                   stop_words='english')\n",
        "t0 = time()\n",
        "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFo0oXQDAoi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use tf (raw term count) features for LDA.\n",
        "print(\"Extracting tf features for LDA...\")\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
        "                                max_features=n_features,\n",
        "                                stop_words='english')\n",
        "t0 = time()\n",
        "tf = tf_vectorizer.fit_transform(data_samples)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcg8P5F_ifFQ",
        "colab_type": "text"
      },
      "source": [
        "# Fit the NMF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYN4BgApigF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
        "      \"n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "t0 = time()\n",
        "nmf = NMF(n_components=n_components, random_state=1,\n",
        "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "print_top_words(nmf, tfidf_feature_names, n_top_words)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXF837lIijDd",
        "colab_type": "text"
      },
      "source": [
        "# Fit the NMF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evy9N4cUikyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
        "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "t0 = time()\n",
        "nmf = NMF(n_components=n_components, random_state=1,\n",
        "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
        "          l1_ratio=.5).fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
        "\n",
        "print(\"Fitting LDA models with tf features, \"\n",
        "      \"n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
        "                                learning_method='online',\n",
        "                                learning_offset=50.,\n",
        "                                random_state=0)\n",
        "t0 = time()\n",
        "lda.fit(tf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "\n",
        "print(\"\\nTopics in LDA model:\")\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "print_top_words(lda, tf_feature_names, n_top_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ7yVgRCBIRW",
        "colab_type": "text"
      },
      "source": [
        "Homework2. Analyzing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2HWSos5CMvG",
        "colab_type": "text"
      },
      "source": [
        "Analyzing classifier Performance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZXAv4DwBRy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze_model(model=None, folds=10):\n",
        "''' Run x-validation and return scores, averaged confusion matrix, and df with false positives and negatives '''\n",
        "\n",
        "X, y, X_test = load()\n",
        "y = y.values   # to numpy\n",
        "X = X.values\n",
        "if not model:\n",
        "    model = load_model()\n",
        "\n",
        "# Manual x-validation to accumulate actual\n",
        "cv_skf = StratifiedKFold(y, n_folds=folds, shuffle=False, random_state=42)\n",
        "scores = []\n",
        "conf_mat = np.zeros((2, 2))      # Binary classification\n",
        "false_pos = Set()\n",
        "false_neg = Set()\n",
        "\n",
        "for train_i, val_i in cv_skf:\n",
        "    X_train, X_val = X[train_i], X[val_i]\n",
        "    y_train, y_val = y[train_i], y[val_i]\n",
        "\n",
        "    print \"Fitting fold...\"\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print \"Predicting fold...\"\n",
        "    y_pprobs = model.predict_proba(X_val)       # Predicted probabilities\n",
        "    y_plabs = np.squeeze(model.predict(X_val))  # Predicted class labels\n",
        "\n",
        "    scores.append(roc_auc_score(y_val, y_pprobs[:, 1]))\n",
        "    confusion = confusion_matrix(y_val, y_plabs)\n",
        "    conf_mat += confusion\n",
        "\n",
        "    # Collect indices of false positive and negatives\n",
        "    fp_i = np.where((y_plabs==1) & (y_val==0))[0]\n",
        "    fn_i = np.where((y_plabs==0) & (y_val==1))[0]\n",
        "    false_pos.update(val_i[fp_i])\n",
        "    false_neg.update(val_i[fn_i])\n",
        "\n",
        "    print \"Fold score: \", scores[-1]\n",
        "    print \"Fold CM: \\n\", confusion\n",
        "\n",
        "print \"\\nMean score: %0.2f (+/- %0.2f)\" % (np.mean(scores), np.std(scores) * 2)\n",
        "conf_mat /= folds\n",
        "print \"Mean CM: \\n\", conf_mat\n",
        "print \"\\nMean classification measures: \\n\"\n",
        "pprint(class_report(conf_mat))\n",
        "return scores, conf_mat, {'fp': sorted(false_pos), 'fn': sorted(false_neg)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-eb4xZNCOrS",
        "colab_type": "text"
      },
      "source": [
        "Calculates average score and calculates averaged confusion-matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-NnOKM1CP_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def class_report(conf_mat):\n",
        "    tp, fp, fn, tn = conf_mat.flatten()\n",
        "    measures = {}\n",
        "    measures['accuracy'] = (tp + tn) / (tp + fp + fn + tn)\n",
        "    measures['specificity'] = tn / (tn + fp)        # (true negative rate)\n",
        "    measures['sensitivity'] = tp / (tp + fn)        # (recall, true positive rate)\n",
        "    measures['precision'] = tp / (tp + fp)\n",
        "    measures['f1score'] = 2*tp / (2*tp + fp + fn)\n",
        "    return measures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FPnjkzzGlyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordlist = data_samples[0].split() \n",
        "BigString = ' '.join(data_samples)\n",
        "wordfreq = []\n",
        "for w in BigString:\n",
        "    wordfreq.append(wordlist.count(w))\n",
        "str(list(zip(wordlist, wordfreq)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGEJCcZjhLvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data_samples = data[:n_samples]\n",
        "\n",
        "print(\"Extracting tf-idf features for NMF...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
        "                                   max_features=n_features,\n",
        "                                   stop_words='english')\n",
        "t0 = time()\n",
        "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}